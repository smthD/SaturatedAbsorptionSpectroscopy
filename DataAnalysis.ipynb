{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Misc. Data Analysis\n",
    "\n",
    "This file contains various smaller chunks of code used for figures and analysis."
   ],
   "id": "f9b52bef638670b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter, find_peaks"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# The first time data from the scope is loaded, the first 21 lines of header need to be chopped off\n",
    "\n",
    "# for i in range(0, 57):\n",
    "#     file_path = f\"tek{i:04}ALL.csv\"\n",
    "#     with open(file_path, \"r\"\n",
    "#               ) as file:\n",
    "#         lines = file.readlines()[21:]  # Skip the first 21 lines\n",
    "#     with open(file_path, \"w\") as file:\n",
    "#         file.writelines(lines)"
   ],
   "id": "a591502d153cf817"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperfine Splitting",
   "id": "a24ea94280f2e088"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## Load Hyperfine Data\n",
    "\n",
    "data = []\n",
    "scope = []\n",
    "arr = np.loadtxt(f\"tek0000ALL.csv\",\n",
    "                 delimiter=\",\", dtype=str)\n",
    "\n",
    "data.append(arr[2:, 0].astype(float)) # Append common time\n",
    "scope.append(arr[2:, 0].astype(float))\n",
    "for i in range(0, 50):\n",
    "    arr = np.loadtxt(f\"tek{i:04}ALL.csv\",\n",
    "                 delimiter=\",\", dtype=str)\n",
    "    data.append(arr[2:, 1].astype(float))\n",
    "    scope.append(arr[2:, 2].astype(float))\n",
    "data = np.array(data).T\n",
    "scope = np.array(scope).T\n"
   ],
   "id": "aa7015f522071e32"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## Large Hyperfine Spacing Figure\n",
    "\n",
    "def filter_by_limit(X, Y, min_val, max_val):\n",
    "    X1 = [i for i in X if min_val <= i <= max_val]\n",
    "    Y1 = [Y[i] for i, x in enumerate(X) if min_val <= x <= max_val]\n",
    "    return np.array(X1), np.array(Y1)\n",
    "\n",
    "L = .539  # Cavity Length\n",
    "c = 299792458\n",
    "FC = c / (2 * L) * 1e-6\n",
    "\n",
    "x, y = filter_by_limit(data[:, 0], data[:, 1], -0.053, -.003)\n",
    "sx, sy = filter_by_limit(scope[:, 0], scope[:, 1] * 2.5, -0.053, -.003)\n",
    "\n",
    "x = (x - np.min(x))\n",
    "sx = (sx - np.min(sx))\n",
    "\n",
    "shift = 0.4\n",
    "y = y - np.min(y)\n",
    "sy = sy - np.min(sy) + shift\n",
    "\n",
    "peaks, _ = find_peaks(sy, prominence=0.01, distance=100)\n",
    "\n",
    "xpeaks = x[peaks]\n",
    "spacing = [xpeaks[i] - xpeaks[i - 1] for i in range(1, len(xpeaks))]\n",
    "mean_spacing = np.mean(spacing) # Calculate Mhz/ms conversion from mean spacing. This isn't quite accurate due to nonlinearity, but is approximately correct\n",
    "\n",
    "peaks, _ = find_peaks(y, prominence=0.01, distance=50)\n",
    "print(x[peaks]*FC/mean_spacing)\n",
    "x = x * FC / mean_spacing\n",
    "sx = sx * FC / mean_spacing\n",
    "\n",
    "# Split points for x-axis break\n",
    "x1_mask = x < 1000\n",
    "x2_mask = x > 6000\n",
    "\n",
    "scope_color = 'white'\n",
    "sas_color = 'black'\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(13, x6), gridspec_kw={'width_ratios': [3, 3]})\n",
    "\n",
    "# First subplot (x < 1000)\n",
    "ax1.plot(x[x1_mask], y[x1_mask], label=\"Data\", color=sas_color)\n",
    "ax1.set_xlim([np.min(x[x1_mask]), np.max(x[x1_mask])])\n",
    "\n",
    "# Second subplot (x > 6000)\n",
    "off = .06\n",
    "ax2.plot(x[x2_mask], y[x2_mask]-off, label=\"Data\", color=sas_color)\n",
    "ax2.set_xlim([np.min(x[x2_mask]), np.max(x[x2_mask])])\n",
    "\n",
    "C = [\"#1F77B4\", \"#FF7F0E\", \"#2CA02C\", \"#D62728\", \"#9467BD\", \"#8C564B\"]\n",
    "fs = 18\n",
    "ax1.annotate(\n",
    "    r'$2 \\to 1 (a)$',\n",
    "    xy=(279, .13),  # Point to annotate\n",
    "    xytext=(210, .35), # Text position\n",
    "    arrowprops=dict(color=C[0], shrink=0.01, width=.01, headwidth=5, headlength=5),\n",
    "    fontsize=fs,\n",
    "    color=C[0],weight='bold'\n",
    "\n",
    ")\n",
    "ax1.annotate(\n",
    "    r'$2 \\to 2 (b)$',\n",
    "    xy=(439, .13),  # Point to annotate\n",
    "    xytext=(360, .38), # Text position\n",
    "    arrowprops=dict(color=C[1], shrink=0.01, width=.01, headwidth=5, headlength=5),\n",
    "    fontsize=fs,\n",
    "    color=C[1],weight='bold'\n",
    "\n",
    ")\n",
    "ax1.annotate(\n",
    "    r'$2 \\to 3 (c)$',\n",
    "    xy=(706, .1),  # Point to annotate\n",
    "    xytext=(706,.35), # Text position\n",
    "    arrowprops=dict(color=C[2], shrink=0.01, width=.01, headwidth=5, headlength=5),\n",
    "    fontsize=fs,\n",
    "    color=C[2],weight='bold'\n",
    "\n",
    ")\n",
    "ax2.annotate(\n",
    "    r'$1 \\to 0 (d)$',\n",
    "    xy=(6914, .09),  # Point to annotate\n",
    "    xytext=(6914, .40), # Text position\n",
    "    arrowprops=dict(color=C[3], shrink=0.01, width=.01, headwidth=5, headlength=5),\n",
    "    fontsize=fs,\n",
    "    color=C[3],weight='bold'\n",
    "\n",
    ")\n",
    "ax2.annotate(\n",
    "    r'$1 \\to 1 (e)$',\n",
    "    xy=(6988, .1),  # Point to annotate\n",
    "    xytext=(6988, .37), # Text position\n",
    "    arrowprops=dict(color=C[4], shrink=0.01, width=.01, headwidth=5, headlength=5),\n",
    "    fontsize=fs,\n",
    "    color=C[4],weight='bold'\n",
    ")\n",
    "ax2.annotate(\n",
    "    r'$1 \\to 2 (f)$',\n",
    "    xy=(7138, .12),  # Point to annotate\n",
    "    xytext=(7040, .32), # Text position\n",
    "    arrowprops=dict(color=C[5], shrink=0.01, width=.01, headwidth=5, headlength=5),\n",
    "    fontsize=fs,\n",
    "    color=C[5],weight='bold'\n",
    ")\n",
    "\n",
    "# Break marks\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax2.spines['left'].set_visible(False)\n",
    "ax1.yaxis.tick_left()\n",
    "ax2.yaxis.tick_right()\n",
    "ax2.yaxis.set_label_position(\"right\")\n",
    "\n",
    "# Add slanted break markers\n",
    "d = .010  # Size of diagonal lines\n",
    "kwargs = dict(transform=ax1.transAxes, color='k', clip_on=False)\n",
    "ax1.plot((1 - d, 1 + d), (-d, +d), **kwargs)\n",
    "ax1.plot((1 - d, 1 + d), (1 - d, 1 + d), **kwargs)\n",
    "\n",
    "kwargs.update(transform=ax2.transAxes)\n",
    "ax2.plot((-d, +d), (-d, +d), **kwargs)\n",
    "ax2.plot((-d, +d), (1 - d, 1 + d), **kwargs)\n",
    "\n",
    "ax1.set_xlabel('Detuning (MHz)', fontsize=16)\n",
    "ax1.set_ylabel('Signal')\n",
    "ax2.get_yaxis().set_visible(False)\n",
    "ax1.get_yaxis().set_visible(False)\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), fontsize=16)\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('FreqSpectrum.png')"
   ],
   "id": "189f2e6679112683"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## Analysis of results of HyperfinePeakGUI.py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def uncertainty(d): # Uncertainty Propagaion\n",
    "    L = .539 # Cavity Length\n",
    "    dL = .001 # Cavity uncertainty\n",
    "    c = 299792458\n",
    "    fsr = c/(2*L)\n",
    "    m = np.mean(d)\n",
    "    return m*(c/(2*L**2))*dL*1e-6\n",
    "\n",
    "L = .539 # Cavity Length\n",
    "dL = .001 # Cavity uncertainty\n",
    "c = 299792458\n",
    "FC = c*(1.000293) / (2*L)\n",
    "arr = np.loadtxt(f\"data.csv\", # Load output from HyperfinePeakGUI\n",
    "             delimiter=\",\", dtype=float)\n",
    "\n",
    "s1 = uncertainty(arr[:, 0])\n",
    "arr[:, 0] = arr[:, 0]*FC*1e-6\n",
    "\n",
    "s2 = uncertainty(arr[:, 1])\n",
    "arr[:, 1] = arr[:, 1]*FC*1e-6\n",
    "\n",
    "s3 = uncertainty(arr[:, 2])\n",
    "arr[:, 2] = arr[:, 2]*FC*1e-6\n",
    "\n",
    "s4 = uncertainty(arr[:, 3])\n",
    "arr[:, 3] = arr[:, 3]*FC*1e-6\n",
    "\n",
    "s5 = uncertainty(arr[:, 4])\n",
    "arr[:, 4] = arr[:, 4]*FC*1e-6\n",
    "\n",
    "s6 = uncertainty(arr[:, 5])\n",
    "arr[:, 5] = arr[:, 5]*FC*1e-6\n",
    "\n",
    "N = np.sqrt(np.size(arr[:, 0]))\n",
    "\n",
    "print(f'B->C: {np.mean(arr[:, 0])} +- {np.std(arr[:, 0])} +- {s1}, % Error: {100*(np.abs(np.mean(arr[:, 0]) - 267.1))/267.1 }')\n",
    "print(f'A->B: {np.mean(arr[:, 1])} +- {np.std(arr[:, 1])} +- {s2}, % Error: {100*(np.abs(np.mean(arr[:, 1]) - 157.2))/157.2}')\n",
    "print(f'E->F: {np.mean(arr[:, 2])} +- {np.std(arr[:, 2])}+- {s3}, % Error: {100*(np.abs(np.mean(arr[:, 2]) - 157.2))/157.2}')\n",
    "print(f'F->C: {np.mean(arr[:, 3])} +- {np.std(arr[:, 3])}+- {s4}, % Error: {100*(np.abs(np.mean(arr[:, 3]) - 6834.7))/6834.7}')\n",
    "print(f'A->E: {np.mean(arr[:, 4])} +- {np.std(arr[:, 4])} +- {s5}, % Error: {100*(np.abs(np.mean(arr[:, 4]) - 6834.7))/6834.7}')\n",
    "print(f'D->E: {np.mean(arr[:, 5])} +- {np.std(arr[:, 5])/N}+- {s6}, % Error: {100*(np.abs(np.mean(arr[:, 5]) - 72.218))/72.218}')\n",
    "\n",
    "fig, ax = plt.subplots(1, 6, figsize=(25, 5))\n",
    "true_values = [267.1, 157.2, 157.2, 6834.7, 6834.7, 72.218]\n",
    "labels = ['B->', 'A->B', 'E->F', 'F->C', 'A->E', 'D->E']\n",
    "for i in range(6):\n",
    "    ax[i].hist(arr[:, i], bins=20)\n",
    "    ax[i].set_title(labels[i])\n",
    "    ax[i].axvline(true_values[i], color='r', linestyle='--')\n",
    "    ax[i].set_xlabel('Mhz')\n"
   ],
   "id": "6ea53b9fbd38f456"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## Frequency conversion factor over each frequency sweep\n",
    "\n",
    "def filter_by_limit(X, Y, min , max):\n",
    "    X1 = [i for i in X if min <= i <= max]\n",
    "    Y1 = [Y[i] for i, x in enumerate(X) if min <= x <= max]\n",
    "    return np.array(X1), np.array(Y1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for k in range(1, 100):\n",
    "    x, y = filter_by_limit(scope[:, 0]-np.min(scope[:, 0]), scope[:, k], 0.02, 0.08)\n",
    "    y = savgol_filter(y, polyorder=2, window_length=100)\n",
    "\n",
    "    peaks, _ = find_peaks(y, prominence=0.01, distance = 20) # Find scope peaks\n",
    "    peakx = x[peaks]\n",
    "    spacing = [peakx[i] - peakx[i - 1] for i in range(1, len(peakx))] # Find time spacing between peaks\n",
    "    x_mean = []\n",
    "    for i in range(np.size(peakx)-1):\n",
    "        x_mean.append(peakx[i] + spacing[i]/2) # X value is right in between each individual interferometer cycle\n",
    "    ax.plot(np.array(x_mean)*1000, FC/(np.array(spacing)*1000), alpha = .3) # Convert to Mhz/Ms -- FC = Mhz/Cycle, so  (Mhz/Cycle) / (ms/cycle) = Mhz/ms\n",
    "ax.set_xlabel(\"Time (ms)\")\n",
    "ax.set_ylabel(\"Mhz/ms\")\n",
    "\n",
    "fig.savefig('peak_spacing.png')"
   ],
   "id": "3ee085e032079b13"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Zeeman Splitting",
   "id": "7a0ddd0d6a21e3d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## Load Zeeman Data\n",
    "data = []\n",
    "scope = []\n",
    "arr = np.loadtxt(f\"tek0000ALL.csv\",\n",
    "                 delimiter=\",\", dtype=str)\n",
    "\n",
    "data.append(arr[2:, 0].astype(float)) # Append common time\n",
    "scope.append(arr[2:, 0].astype(float))\n",
    "for i in range(0, 57):\n",
    "    if i != 15: # Data 15 was corrupted\n",
    "        arr = np.loadtxt(f\"tek{i:04}ALL.csv\",\n",
    "                     delimiter=\",\", dtype=str)\n",
    "        data.append(arr[2:, 1].astype(float))\n",
    "        scope.append(arr[2:, 2].astype(float))\n",
    "data = np.array(data).T\n",
    "scope = np.array(scope).T"
   ],
   "id": "fc45fb0903cf1c3d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# For Zeeman analysis, the calibration is taken from the spacing between the  P3/2 F = 1 to F = 2 hyperfine transitions. The time between the first and last peak in this trace corresponds to 156.9477 Mhz\n",
    "\n",
    "fig ,ax = plt.subplots()\n",
    "\n",
    "fy = savgol_filter(data[:, 1], 100, 2)\n",
    "peaks, _ = find_peaks(fy, prominence=0.001, distance = 10)\n",
    "\n",
    "for p in peaks:\n",
    "    ax.axvline(data[:,0][p], color='r')\n",
    "ax.plot(data[:, 0], fy)\n",
    "print(data[:, 0][peaks])\n"
   ],
   "id": "c574cd2e17a1416c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## Plot of various Zeeman Splittings at different magnetic fields\n",
    "\n",
    "def filter_by_limit(Y, min , max):\n",
    "    Y1 = [Y[i] for i, x in enumerate(data[:, 0]) if min <= x <= max]\n",
    "    return np.array(Y1)\n",
    "\n",
    "# Defne x-axis in MHZ relative to unshifted peak location\n",
    "maxx = .415; minn = .413\n",
    "x = (np.array([i for i in data[:, 0] if minn <= i <= maxx])-.4137853)*156.94/(.4137853 - .4113364)\n",
    "\n",
    "# Prepare data in dictionary format for joyplot\n",
    "data_dict = {'0 g' : savgol_filter(filter_by_limit(data[:, 1], minn, maxx), 500, 2),\n",
    "             '10 g' : savgol_filter(filter_by_limit(data[:, 2], minn, maxx), 500, 2),\n",
    "             '20 g' : savgol_filter(filter_by_limit(data[:, 17], minn, maxx), 500, 2),\n",
    "             '30 g' : savgol_filter(filter_by_limit(data[:, 32], minn, maxx), 500, 2),\n",
    "             '52 g' : savgol_filter(filter_by_limit(data[:, 42], minn, maxx), 500, 2),\n",
    "             '72 g' : savgol_filter(filter_by_limit(data[:, 48], minn, maxx), 500, 2),\n",
    "             '90 g' : savgol_filter(filter_by_limit(data[:, 56], minn, maxx), 500, 2)}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "shift = .008\n",
    "ax.plot(x, data_dict['0 g'], label='0 g')\n",
    "ax.plot(x, data_dict['10 g']+(shift-.002), label='10 g')\n",
    "ax.plot(x, data_dict['20 g']+2*(shift-.001), label='10 g')\n",
    "ax.plot(x, data_dict['30 g']+3*(shift-.0005), label='10 g')\n",
    "\n",
    "ax.text(x = 70, y =data_dict['0 g'][-1]+.0005, s= '0 G')\n",
    "ax.text(x = 70, y =data_dict['10 g'][-1]+(shift-.0018), s= '10 G')\n",
    "ax.text(x = 70, y =data_dict['20 g'][-1]+2*(shift-.0008), s= '20 G')\n",
    "ax.text(x = 70, y =data_dict['30 g'][-1]+3*(shift-.0002), s= '30 G')\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.grid(False)\n",
    "ax.set_xlabel(\"Detuning (Mhz)\")"
   ],
   "id": "ce4116fe0b00d1f6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
